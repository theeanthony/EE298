{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungal Signal Vocabulary Discovery Pipeline\n",
    "**EE297B Research Project — SJSU**  \n",
    "Anthony Contreras & Alex Wong\n",
    "\n",
    "Run this notebook on **Google Colab (GPU runtime)** to:\n",
    "1. Download all datasets (Adamatzky, Buffi, ECG)\n",
    "2. Discover fungal signal vocabulary (k-means clustering)\n",
    "3. Train TCN Phase 1 (ECG pre-training)\n",
    "4. Train TCN Phase 2 (vocabulary classification)\n",
    "5. Train TCN Phase 3 (stimulus response decoding)\n",
    "6. Build word→stimulus dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 — Setup: Clone repo + install deps\n",
    "Run this first. Takes ~1 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repo\n",
    "!git clone https://github.com/theeanthony/EE298.git /content/EE298 2>/dev/null || (cd /content/EE298 && git pull)\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q scikit-learn joblib pandas numpy scipy matplotlib torch h5py gdown psutil\n",
    "\n",
    "# Verify GPU\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "os.chdir('/content/EE298/software/ml')\n",
    "print(f\"\\nWorking dir: {os.getcwd()}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 — Download all datasets\n",
    "Downloads Adamatzky (Zenodo), Buffi (Mendeley), and ECG (Kaggle).  \n",
    "~1.5 GB total. Takes ~3-5 min on Colab.\n",
    "\n",
    "**Note:** ECG requires Kaggle API token. If you don't have one, follow the printed instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/EE298/software/ml')\n",
    "\n",
    "# Download Adamatzky + Buffi\n",
    "!python download_data.py\n",
    "\n",
    "# Download ECG (for Phase 1 pre-training)\n",
    "# Option A: If you have kaggle CLI configured\n",
    "!python download_pretrain_data.py --ecg\n",
    "\n",
    "# Option B: If Kaggle CLI fails, uncomment these lines to download manually:\n",
    "# !pip install -q kaggle\n",
    "# !mkdir -p ~/.kaggle\n",
    "# # Upload your kaggle.json to Colab first, then:\n",
    "# # from google.colab import files; uploaded = files.upload()  # upload kaggle.json\n",
    "# # !mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle datasets download -d shayanfazeli/heartbeat -p ../../data/external/ecg_heartbeat --unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 — Verify data is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_root = '/content/EE298/data/external'\n",
    "\n",
    "# Adamatzky\n",
    "adam_dir = os.path.join(data_root, 'adamatzky')\n",
    "adam_files = []\n",
    "for root, dirs, files in os.walk(adam_dir):\n",
    "    for f in files:\n",
    "        if f.endswith('.txt') and '__MACOSX' not in root:\n",
    "            adam_files.append(f)\n",
    "print(f\"Adamatzky: {len(adam_files)} .txt files\")\n",
    "for f in adam_files:\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "# Buffi\n",
    "buffi_dir = os.path.join(data_root, 'buffi')\n",
    "buffi_files = [f for f in os.listdir(buffi_dir) if f.endswith('.hdf5')] if os.path.exists(buffi_dir) else []\n",
    "print(f\"\\nBuffi: {len(buffi_files)} .hdf5 files\")\n",
    "for f in sorted(buffi_files):\n",
    "    size_mb = os.path.getsize(os.path.join(buffi_dir, f)) / (1024*1024)\n",
    "    print(f\"  {f} ({size_mb:.0f} MB)\")\n",
    "\n",
    "# ECG\n",
    "ecg_dir = os.path.join(data_root, 'ecg_heartbeat')\n",
    "ecg_ok = os.path.exists(os.path.join(ecg_dir, 'mitbih_train.csv'))\n",
    "print(f\"\\nECG: {'FOUND' if ecg_ok else 'MISSING — Phase 1 will be skipped'}\")\n",
    "\n",
    "# Synthetic\n",
    "syn_dir = '/content/EE298/data/synthetic'\n",
    "syn_ok = os.path.exists(os.path.join(syn_dir, 'manifest.csv'))\n",
    "print(f\"Synthetic: {'FOUND' if syn_ok else 'MISSING — run synthetic_data.py if needed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 — Generate synthetic data (if missing)\n",
    "Only needed if Cell 3 shows synthetic as MISSING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/EE298/software/ml')\n",
    "\n",
    "if not os.path.exists('/content/EE298/data/synthetic/manifest.csv'):\n",
    "    !python synthetic_data.py\n",
    "else:\n",
    "    print(\"Synthetic data already exists, skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 — Discover Fungal Vocabulary\n",
    "Runs Adamatzky's methodology: detect spikes → group into words → cluster into vocabulary.  \n",
    "Takes ~2-5 min depending on data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/EE298/software/ml')\n",
    "\n",
    "# Discover vocabulary with k=50 clusters (Adamatzky found ~50 word types)\n",
    "!python spike_vocabulary.py --n-clusters 50 --max-rows 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5b (optional) — Elbow plot to find optimal k\n",
    "Run this if you want to see if k=50 is the right choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/EE298/software/ml')\n",
    "\n",
    "# Elbow method — tests k=5,10,15,...,80\n",
    "!python spike_vocabulary.py --elbow --max-rows 0\n",
    "\n",
    "# Display the elbow plot\n",
    "from IPython.display import Image, display\n",
    "elbow_path = '/content/EE298/data/ml_results/vocabulary_elbow.png'\n",
    "if os.path.exists(elbow_path):\n",
    "    display(Image(filename=elbow_path, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5c — View vocabulary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/EE298/software/ml')\n",
    "\n",
    "# Show vocabulary stats\n",
    "!python spike_vocabulary.py --analyze\n",
    "\n",
    "# Display the analysis plots\n",
    "from IPython.display import Image, display\n",
    "plot_path = '/content/EE298/data/ml_results/vocabulary_analysis.png'\n",
    "if os.path.exists(plot_path):\n",
    "    display(Image(filename=plot_path, width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 — Train TCN (Vocabulary Mode, All 3 Phases)\n",
    "- **Phase 1:** ECG pre-training (5-class heartbeat, ~5 min)\n",
    "- **Phase 2:** Vocabulary classification (k-class word types, ~5 min)\n",
    "- **Phase 3:** Stimulus response decoding (5-class: 4 stimuli + baseline, ~5 min)\n",
    "\n",
    "Total: ~15-20 min on T4 GPU with `--full`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/EE298/software/ml')\n",
    "\n",
    "# Run all 3 phases with Colab-optimized settings\n",
    "!python train_tcn.py --mode vocabulary --phase all --full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to run phases individually:\n",
    "Uncomment the phase you want to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/content/EE298/software/ml')\n",
    "\n",
    "# Phase 1 only (ECG pre-training)\n",
    "# !python train_tcn.py --mode vocabulary --phase 1 --full\n",
    "\n",
    "# Phase 2 only (vocabulary classification)\n",
    "# !python train_tcn.py --mode vocabulary --phase 2 --full\n",
    "\n",
    "# Phase 3 only (stimulus response)\n",
    "# !python train_tcn.py --mode vocabulary --phase 3 --full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 — Build Fungal Dictionary\n",
    "Maps discovered word types to stimulus meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/EE298/software/ml')\n",
    "\n",
    "!python build_dictionary.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7b — View the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dict_path = '/content/EE298/software/ml/models/fungal_dictionary.json'\n",
    "if os.path.exists(dict_path):\n",
    "    with open(dict_path) as f:\n",
    "        d = json.load(f)\n",
    "    print(f\"Vocabulary size: {d['vocabulary_size']} word types\")\n",
    "    print(f\"Stimuli: {d['stimuli']}\")\n",
    "    print()\n",
    "    \n",
    "    # Top 15 most confident word→stimulus mappings\n",
    "    words = sorted(d['words'].items(), key=lambda x: x[1]['confidence'], reverse=True)\n",
    "    print(f\"{'Word':<10} {'Occurrences':<14} {'Primary Stimulus':<20} {'Confidence':<12} {'Interpretation'}\")\n",
    "    print('-' * 90)\n",
    "    for wtype, info in words[:15]:\n",
    "        print(f\"word_{wtype:<5} {info['total_occurrences']:<14} {info['primary_stimulus']:<20} \"\n",
    "              f\"{info['confidence']:<12.3f} {info['interpretation']}\")\n",
    "else:\n",
    "    print(\"Dictionary not found — run Cell 7 first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8 — Download results to your Mac\n",
    "Downloads the trained models and dictionary so you can use them locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip up the results\n",
    "results_dir = '/content/EE298/software/ml/models'\n",
    "plots_dir = '/content/EE298/data/ml_results'\n",
    "\n",
    "# Create a zip with all outputs\n",
    "!cd /content/EE298 && zip -r /content/vocabulary_results.zip \\\n",
    "    software/ml/models/tcn_phase1_ecg.pt \\\n",
    "    software/ml/models/tcn_phase2_vocabulary.pt \\\n",
    "    software/ml/models/tcn_phase3_stimulus.pt \\\n",
    "    software/ml/models/vocabulary_kmeans.joblib \\\n",
    "    software/ml/models/vocabulary_scaler.joblib \\\n",
    "    software/ml/models/vocabulary_labels.npz \\\n",
    "    software/ml/models/fungal_dictionary.json \\\n",
    "    data/ml_results/ \\\n",
    "    2>/dev/null\n",
    "\n",
    "zip_size = os.path.getsize('/content/vocabulary_results.zip') / (1024*1024)\n",
    "print(f\"\\nResults zip: {zip_size:.1f} MB\")\n",
    "print(\"\\nFiles included:\")\n",
    "!zipinfo -1 /content/vocabulary_results.zip\n",
    "\n",
    "# Auto-download in Colab browser\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('/content/vocabulary_results.zip')\n",
    "except ImportError:\n",
    "    print(\"\\nNot running in Colab browser — manually download:\")\n",
    "    print(\"  /content/vocabulary_results.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9 (optional) — Also run the binary baseline for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/EE298/software/ml')\n",
    "\n",
    "# Binary mode (original smoke detector)\n",
    "# !python train_tcn.py --mode binary --phase all --full\n",
    "\n",
    "# Classical ML baseline\n",
    "# !python train.py --full"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
